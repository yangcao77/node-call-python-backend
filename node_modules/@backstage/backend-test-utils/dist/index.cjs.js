'use strict';

var Keyv = require('keyv');
var KeyvMemcache = require('@keyv/memcache');
var uuid = require('uuid');
var KeyvRedis = require('@keyv/redis');
var errors = require('@backstage/errors');
var crypto = require('crypto');
var knexFactory = require('knex');
var yn = require('yn');
var pgConnectionString = require('pg-connection-string');
var os = require('os');
var backendPluginApi = require('@backstage/backend-plugin-api');
var fs = require('fs-extra');
var textextensions = require('textextensions');
var path = require('path');
var backendAppApi = require('@backstage/backend-app-api');
var cache = require('@backstage/backend-defaults/cache');
var database = require('@backstage/backend-defaults/database');
var discovery = require('@backstage/backend-defaults/discovery');
var httpRouter = require('@backstage/backend-defaults/httpRouter');
var lifecycle = require('@backstage/backend-defaults/lifecycle');
var logger = require('@backstage/backend-defaults/logger');
var permissions = require('@backstage/backend-defaults/permissions');
var rootHealth = require('@backstage/backend-defaults/rootHealth');
var rootHttpRouter = require('@backstage/backend-defaults/rootHttpRouter');
var rootLifecycle = require('@backstage/backend-defaults/rootLifecycle');
var scheduler = require('@backstage/backend-defaults/scheduler');
var urlReader = require('@backstage/backend-defaults/urlReader');
var config = require('@backstage/config');
var pluginEventsNode = require('@backstage/plugin-events-node');
var cookie = require('cookie');
var express = require('express');

function _interopDefaultCompat (e) { return e && typeof e === 'object' && 'default' in e ? e : { default: e }; }

var Keyv__default = /*#__PURE__*/_interopDefaultCompat(Keyv);
var KeyvMemcache__default = /*#__PURE__*/_interopDefaultCompat(KeyvMemcache);
var KeyvRedis__default = /*#__PURE__*/_interopDefaultCompat(KeyvRedis);
var knexFactory__default = /*#__PURE__*/_interopDefaultCompat(knexFactory);
var yn__default = /*#__PURE__*/_interopDefaultCompat(yn);
var os__default = /*#__PURE__*/_interopDefaultCompat(os);
var fs__default = /*#__PURE__*/_interopDefaultCompat(fs);
var textextensions__default = /*#__PURE__*/_interopDefaultCompat(textextensions);
var express__default = /*#__PURE__*/_interopDefaultCompat(express);

function registerMswTestHooks(worker) {
  beforeAll(() => worker.listen({ onUnhandledRequest: "error" }));
  afterAll(() => worker.close());
  afterEach(() => worker.resetHandlers());
}

function isDockerDisabledForTests$1() {
  return Boolean(process.env.BACKSTAGE_TEST_DISABLE_DOCKER) || !Boolean(process.env.CI);
}

function setupRequestMockHandlers(worker) {
  registerMswTestHooks(worker);
}
function isDockerDisabledForTests() {
  return isDockerDisabledForTests$1();
}

async function attemptMemcachedConnection(connection) {
  const startTime = Date.now();
  for (; ; ) {
    try {
      const store = new KeyvMemcache__default.default(connection);
      const keyv = new Keyv__default.default({ store });
      const value = uuid.v4();
      await keyv.set("test", value);
      if (await keyv.get("test") === value) {
        return keyv;
      }
    } catch (e) {
      if (Date.now() - startTime > 3e4) {
        throw new Error(
          `Timed out waiting for memcached to be ready for connections, ${e}`
        );
      }
    }
    await new Promise((resolve) => setTimeout(resolve, 100));
  }
}
async function connectToExternalMemcache(connection) {
  const keyv = await attemptMemcachedConnection(connection);
  return {
    store: "memcache",
    connection,
    keyv,
    stop: async () => await keyv.disconnect()
  };
}
async function startMemcachedContainer(image) {
  const { GenericContainer } = await import('testcontainers');
  const container = await new GenericContainer(image).withExposedPorts(11211).start();
  const host = container.getHost();
  const port = container.getMappedPort(11211);
  const connection = `${host}:${port}`;
  const keyv = await attemptMemcachedConnection(connection);
  return {
    store: "memcache",
    connection,
    keyv,
    stop: async () => {
      await keyv.disconnect();
      await container.stop({ timeout: 1e4 });
    }
  };
}

async function attemptRedisConnection(connection) {
  const startTime = Date.now();
  for (; ; ) {
    try {
      const store = new KeyvRedis__default.default(connection);
      const keyv = new Keyv__default.default({ store });
      const value = uuid.v4();
      await keyv.set("test", value);
      if (await keyv.get("test") === value) {
        return keyv;
      }
    } catch (e) {
      if (Date.now() - startTime > 3e4) {
        throw new Error(
          `Timed out waiting for redis to be ready for connections, ${e}`
        );
      }
    }
    await new Promise((resolve) => setTimeout(resolve, 100));
  }
}
async function connectToExternalRedis(connection) {
  const keyv = await attemptRedisConnection(connection);
  return {
    store: "redis",
    connection,
    keyv,
    stop: async () => await keyv.disconnect()
  };
}
async function startRedisContainer(image) {
  const { GenericContainer } = await import('testcontainers');
  const container = await new GenericContainer(image).withExposedPorts(6379).start();
  const host = container.getHost();
  const port = container.getMappedPort(6379);
  const connection = `redis://${host}:${port}`;
  const keyv = await attemptRedisConnection(connection);
  return {
    store: "redis",
    connection,
    keyv,
    stop: async () => {
      await keyv.disconnect();
      await container.stop({ timeout: 1e4 });
    }
  };
}

const getDockerImageForName = (name) => {
  return process.env.BACKSTAGE_TEST_DOCKER_REGISTRY ? `${process.env.BACKSTAGE_TEST_DOCKER_REGISTRY}/${name}` : name;
};

const allCaches = Object.freeze({
  REDIS_7: {
    name: "Redis 7.x",
    store: "redis",
    dockerImageName: getDockerImageForName("redis:7"),
    connectionStringEnvironmentVariableName: "BACKSTAGE_TEST_CACHE_REDIS7_CONNECTION_STRING"
  },
  MEMCACHED_1: {
    name: "Memcached 1.x",
    store: "memcache",
    dockerImageName: getDockerImageForName("memcached:1"),
    connectionStringEnvironmentVariableName: "BACKSTAGE_TEST_CACHE_MEMCACHED1_CONNECTION_STRING"
  },
  MEMORY: {
    name: "In-memory",
    store: "memory"
  }
});

class TestCaches {
  instanceById;
  supportedIds;
  static defaultIds;
  /**
   * Creates an empty `TestCaches` instance, and sets up Jest to clean up all of
   * its acquired resources after all tests finish.
   *
   * You typically want to create just a single instance like this at the top of
   * your test file or `describe` block, and then call `init` many times on that
   * instance inside the individual tests. Spinning up a "physical" cache
   * instance takes a considerable amount of time, slowing down tests. But
   * wiping the contents of an instance using `init` is very fast.
   */
  static create(options) {
    const ids = options?.ids;
    const disableDocker = options?.disableDocker ?? isDockerDisabledForTests$1();
    let testCacheIds;
    if (ids) {
      testCacheIds = ids;
    } else if (TestCaches.defaultIds) {
      testCacheIds = TestCaches.defaultIds;
    } else {
      testCacheIds = Object.keys(allCaches);
    }
    const supportedIds = testCacheIds.filter((id) => {
      const properties = allCaches[id];
      if (!properties) {
        return false;
      }
      if (properties.connectionStringEnvironmentVariableName && process.env[properties.connectionStringEnvironmentVariableName]) {
        return true;
      }
      if (!properties.dockerImageName) {
        return true;
      }
      if (disableDocker) {
        return false;
      }
      return true;
    });
    const caches = new TestCaches(supportedIds);
    if (supportedIds.length > 0) {
      afterAll(async () => {
        await caches.shutdown();
      });
    }
    return caches;
  }
  static setDefaults(options) {
    TestCaches.defaultIds = options.ids;
  }
  constructor(supportedIds) {
    this.instanceById = /* @__PURE__ */ new Map();
    this.supportedIds = supportedIds;
  }
  supports(id) {
    return this.supportedIds.includes(id);
  }
  eachSupportedId() {
    return this.supportedIds.map((id) => [id]);
  }
  /**
   * Returns a fresh, empty cache for the given driver.
   *
   * @param id - The ID of the cache to use, e.g. 'REDIS_7'
   * @returns Cache connection properties
   */
  async init(id) {
    const properties = allCaches[id];
    if (!properties) {
      const candidates = Object.keys(allCaches).join(", ");
      throw new Error(
        `Unknown test cache ${id}, possible values are ${candidates}`
      );
    }
    if (!this.supportedIds.includes(id)) {
      const candidates = this.supportedIds.join(", ");
      throw new Error(
        `Unsupported test cache ${id} for this environment, possible values are ${candidates}`
      );
    }
    let instance = this.instanceById.get(id);
    if (!instance) {
      instance = await this.initAny(properties);
      this.instanceById.set(id, instance);
    }
    await instance.keyv.clear();
    return {
      store: instance.store,
      connection: instance.connection,
      keyv: instance.keyv
    };
  }
  async initAny(properties) {
    switch (properties.store) {
      case "memcache":
        return this.initMemcached(properties);
      case "redis":
        return this.initRedis(properties);
      case "memory":
        return {
          store: "memory",
          connection: "memory",
          keyv: new Keyv__default.default(),
          stop: async () => {
          }
        };
      default:
        throw new Error(`Unknown cache store '${properties.store}'`);
    }
  }
  async initMemcached(properties) {
    const envVarName = properties.connectionStringEnvironmentVariableName;
    if (envVarName) {
      const connectionString = process.env[envVarName];
      if (connectionString) {
        return connectToExternalMemcache(connectionString);
      }
    }
    return await startMemcachedContainer(properties.dockerImageName);
  }
  async initRedis(properties) {
    const envVarName = properties.connectionStringEnvironmentVariableName;
    if (envVarName) {
      const connectionString = process.env[envVarName];
      if (connectionString) {
        return connectToExternalRedis(connectionString);
      }
    }
    return await startRedisContainer(properties.dockerImageName);
  }
  async shutdown() {
    const instances = [...this.instanceById.values()];
    this.instanceById.clear();
    await Promise.all(
      instances.map(
        ({ stop }) => stop().catch((error) => {
          console.warn(`TestCaches: Failed to stop container`, { error });
        })
      )
    );
  }
}

const allDatabases = Object.freeze({
  POSTGRES_16: {
    name: "Postgres 16.x",
    driver: "pg",
    dockerImageName: getDockerImageForName("postgres:16"),
    connectionStringEnvironmentVariableName: "BACKSTAGE_TEST_DATABASE_POSTGRES16_CONNECTION_STRING"
  },
  POSTGRES_15: {
    name: "Postgres 15.x",
    driver: "pg",
    dockerImageName: getDockerImageForName("postgres:15"),
    connectionStringEnvironmentVariableName: "BACKSTAGE_TEST_DATABASE_POSTGRES15_CONNECTION_STRING"
  },
  POSTGRES_14: {
    name: "Postgres 14.x",
    driver: "pg",
    dockerImageName: getDockerImageForName("postgres:14"),
    connectionStringEnvironmentVariableName: "BACKSTAGE_TEST_DATABASE_POSTGRES14_CONNECTION_STRING"
  },
  POSTGRES_13: {
    name: "Postgres 13.x",
    driver: "pg",
    dockerImageName: getDockerImageForName("postgres:13"),
    connectionStringEnvironmentVariableName: "BACKSTAGE_TEST_DATABASE_POSTGRES13_CONNECTION_STRING"
  },
  POSTGRES_12: {
    name: "Postgres 12.x",
    driver: "pg",
    dockerImageName: getDockerImageForName("postgres:12"),
    connectionStringEnvironmentVariableName: "BACKSTAGE_TEST_DATABASE_POSTGRES12_CONNECTION_STRING"
  },
  POSTGRES_11: {
    name: "Postgres 11.x",
    driver: "pg",
    dockerImageName: getDockerImageForName("postgres:11"),
    connectionStringEnvironmentVariableName: "BACKSTAGE_TEST_DATABASE_POSTGRES11_CONNECTION_STRING"
  },
  POSTGRES_9: {
    name: "Postgres 9.x",
    driver: "pg",
    dockerImageName: getDockerImageForName("postgres:9"),
    connectionStringEnvironmentVariableName: "BACKSTAGE_TEST_DATABASE_POSTGRES9_CONNECTION_STRING"
  },
  MYSQL_8: {
    name: "MySQL 8.x",
    driver: "mysql2",
    dockerImageName: getDockerImageForName("mysql:8"),
    connectionStringEnvironmentVariableName: "BACKSTAGE_TEST_DATABASE_MYSQL8_CONNECTION_STRING"
  },
  SQLITE_3: {
    name: "SQLite 3.x",
    driver: "better-sqlite3"
  }
});
const LARGER_POOL_CONFIG = {
  pool: {
    min: 0,
    max: 50
  }
};

async function waitForMysqlReady(connection) {
  const startTime = Date.now();
  let lastError;
  let attempts = 0;
  for (; ; ) {
    attempts += 1;
    let knex;
    try {
      knex = knexFactory__default.default({
        client: "mysql2",
        connection: {
          // make a copy because the driver mutates this
          ...connection
        }
      });
      const result = await knex.select(knex.raw("version() AS version"));
      if (Array.isArray(result) && result[0]?.version) {
        return;
      }
    } catch (e) {
      lastError = e;
    } finally {
      await knex?.destroy();
    }
    if (Date.now() - startTime > 3e4) {
      throw new Error(
        `Timed out waiting for the database to be ready for connections, ${attempts} attempts, ${lastError ? `last error was ${errors.stringifyError(lastError)}` : "(no errors thrown)"}`
      );
    }
    await new Promise((resolve) => setTimeout(resolve, 100));
  }
}
async function startMysqlContainer(image) {
  const user = "root";
  const password = uuid.v4();
  const { GenericContainer } = await import('testcontainers');
  const container = await new GenericContainer(image).withExposedPorts(3306).withEnvironment({ MYSQL_ROOT_PASSWORD: password }).withTmpFs({ "/var/lib/mysql": "rw" }).start();
  const host = container.getHost();
  const port = container.getMappedPort(3306);
  const connection = { host, port, user, password };
  const stopContainer = async () => {
    await container.stop({ timeout: 1e4 });
  };
  await waitForMysqlReady(connection);
  return { connection, stopContainer };
}
function parseMysqlConnectionString(connectionString) {
  try {
    const {
      protocol,
      username,
      password,
      port,
      hostname,
      pathname,
      searchParams
    } = new URL(connectionString);
    if (protocol !== "mysql:") {
      throw new Error(`Unknown protocol ${protocol}`);
    } else if (!username || !password) {
      throw new Error(`Missing username/password`);
    } else if (!pathname.match(/^\/[^/]+$/)) {
      throw new Error(`Expected single path segment`);
    }
    const result = {
      user: username,
      password,
      host: hostname,
      port: Number(port || 3306),
      database: decodeURIComponent(pathname.substring(1))
    };
    const ssl = searchParams.get("ssl");
    if (ssl) {
      result.ssl = ssl;
    }
    const debug = searchParams.get("debug");
    if (debug) {
      result.debug = yn__default.default(debug);
    }
    return result;
  } catch (e) {
    throw new Error(`Error while parsing MySQL connection string, ${e}`, e);
  }
}
class MysqlEngine {
  static async create(properties) {
    const { connectionStringEnvironmentVariableName, dockerImageName } = properties;
    if (connectionStringEnvironmentVariableName) {
      const connectionString = process.env[connectionStringEnvironmentVariableName];
      if (connectionString) {
        const connection = parseMysqlConnectionString(connectionString);
        return new MysqlEngine(
          properties,
          connection
        );
      }
    }
    if (dockerImageName) {
      const { connection, stopContainer } = await startMysqlContainer(
        dockerImageName
      );
      return new MysqlEngine(properties, connection, stopContainer);
    }
    throw new Error(`Test databasee for ${properties.name} not configured`);
  }
  #properties;
  #connection;
  #knexInstances;
  #databaseNames;
  #stopContainer;
  constructor(properties, connection, stopContainer) {
    this.#properties = properties;
    this.#connection = connection;
    this.#knexInstances = [];
    this.#databaseNames = [];
    this.#stopContainer = stopContainer;
  }
  async createDatabaseInstance() {
    const adminConnection = this.#connectAdmin();
    try {
      const databaseName = `db${crypto.randomBytes(16).toString("hex")}`;
      await adminConnection.raw("CREATE DATABASE ??", [databaseName]);
      this.#databaseNames.push(databaseName);
      const knexInstance = knexFactory__default.default({
        client: this.#properties.driver,
        connection: {
          ...this.#connection,
          database: databaseName
        },
        ...LARGER_POOL_CONFIG
      });
      this.#knexInstances.push(knexInstance);
      return knexInstance;
    } finally {
      await adminConnection.destroy();
    }
  }
  async shutdown() {
    for (const instance of this.#knexInstances) {
      await instance.destroy();
    }
    const adminConnection = this.#connectAdmin();
    try {
      for (const databaseName of this.#databaseNames) {
        await adminConnection.raw("DROP DATABASE ??", [databaseName]);
      }
    } finally {
      await adminConnection.destroy();
    }
    await this.#stopContainer?.();
  }
  #connectAdmin() {
    const connection = {
      ...this.#connection,
      database: null
    };
    return knexFactory__default.default({
      client: this.#properties.driver,
      connection,
      pool: {
        acquireTimeoutMillis: 1e4
      }
    });
  }
}

async function waitForPostgresReady(connection) {
  const startTime = Date.now();
  let lastError;
  let attempts = 0;
  for (; ; ) {
    attempts += 1;
    let knex;
    try {
      knex = knexFactory__default.default({
        client: "pg",
        connection: {
          // make a copy because the driver mutates this
          ...connection
        }
      });
      const result = await knex.select(knex.raw("version()"));
      if (Array.isArray(result) && result[0]?.version) {
        return;
      }
    } catch (e) {
      lastError = e;
    } finally {
      await knex?.destroy();
    }
    if (Date.now() - startTime > 3e4) {
      throw new Error(
        `Timed out waiting for the database to be ready for connections, ${attempts} attempts, ${lastError ? `last error was ${errors.stringifyError(lastError)}` : "(no errors thrown)"}`
      );
    }
    await new Promise((resolve) => setTimeout(resolve, 100));
  }
}
async function startPostgresContainer(image) {
  const user = "postgres";
  const password = uuid.v4();
  const { GenericContainer } = await import('testcontainers');
  const container = await new GenericContainer(image).withExposedPorts(5432).withEnvironment({ POSTGRES_PASSWORD: password }).withTmpFs({ "/var/lib/postgresql/data": "rw" }).start();
  const host = container.getHost();
  const port = container.getMappedPort(5432);
  const connection = { host, port, user, password };
  const stopContainer = async () => {
    await container.stop({ timeout: 1e4 });
  };
  await waitForPostgresReady(connection);
  return { connection, stopContainer };
}
class PostgresEngine {
  static async create(properties) {
    const { connectionStringEnvironmentVariableName, dockerImageName } = properties;
    if (connectionStringEnvironmentVariableName) {
      const connectionString = process.env[connectionStringEnvironmentVariableName];
      if (connectionString) {
        const connection = pgConnectionString.parse(connectionString);
        return new PostgresEngine(
          properties,
          connection
        );
      }
    }
    if (dockerImageName) {
      const { connection, stopContainer } = await startPostgresContainer(
        dockerImageName
      );
      return new PostgresEngine(properties, connection, stopContainer);
    }
    throw new Error(`Test databasee for ${properties.name} not configured`);
  }
  #properties;
  #connection;
  #knexInstances;
  #databaseNames;
  #stopContainer;
  constructor(properties, connection, stopContainer) {
    this.#properties = properties;
    this.#connection = connection;
    this.#knexInstances = [];
    this.#databaseNames = [];
    this.#stopContainer = stopContainer;
  }
  async createDatabaseInstance() {
    const adminConnection = this.#connectAdmin();
    try {
      const databaseName = `db${crypto.randomBytes(16).toString("hex")}`;
      await adminConnection.raw("CREATE DATABASE ??", [databaseName]);
      this.#databaseNames.push(databaseName);
      const knexInstance = knexFactory__default.default({
        client: this.#properties.driver,
        connection: {
          ...this.#connection,
          database: databaseName
        },
        ...LARGER_POOL_CONFIG
      });
      this.#knexInstances.push(knexInstance);
      return knexInstance;
    } finally {
      await adminConnection.destroy();
    }
  }
  async shutdown() {
    for (const instance of this.#knexInstances) {
      await instance.destroy();
    }
    const adminConnection = this.#connectAdmin();
    try {
      for (const databaseName of this.#databaseNames) {
        await adminConnection.raw("DROP DATABASE ??", [databaseName]);
      }
    } finally {
      await adminConnection.destroy();
    }
    await this.#stopContainer?.();
  }
  #connectAdmin() {
    return knexFactory__default.default({
      client: this.#properties.driver,
      connection: {
        ...this.#connection,
        database: "postgres"
      },
      pool: {
        acquireTimeoutMillis: 1e4
      }
    });
  }
}

class SqliteEngine {
  static async create(properties) {
    return new SqliteEngine(properties);
  }
  #properties;
  #instances;
  constructor(properties) {
    this.#properties = properties;
    this.#instances = [];
  }
  async createDatabaseInstance() {
    const instance = knexFactory__default.default({
      client: this.#properties.driver,
      connection: ":memory:",
      useNullAsDefault: true
    });
    instance.client.pool.on("createSuccess", (_eventId, resource) => {
      resource.run("PRAGMA foreign_keys = ON", () => {
      });
    });
    this.#instances.push(instance);
    return instance;
  }
  async shutdown() {
    for (const instance of this.#instances) {
      await instance.destroy();
    }
  }
}

class TestDatabases {
  engineFactoryByDriver = {
    pg: PostgresEngine.create,
    mysql: MysqlEngine.create,
    mysql2: MysqlEngine.create,
    "better-sqlite3": SqliteEngine.create,
    sqlite3: SqliteEngine.create
  };
  engineByTestDatabaseId;
  supportedIds;
  static defaultIds;
  /**
   * Creates an empty `TestDatabases` instance, and sets up Jest to clean up
   * all of its acquired resources after all tests finish.
   *
   * You typically want to create just a single instance like this at the top
   * of your test file or `describe` block, and then call `init` many times on
   * that instance inside the individual tests. Spinning up a "physical"
   * database instance takes a considerable amount of time, slowing down tests.
   * But initializing a new logical database inside that instance using `init`
   * is very fast.
   */
  static create(options) {
    const ids = options?.ids;
    const disableDocker = options?.disableDocker ?? isDockerDisabledForTests$1();
    let testDatabaseIds;
    if (ids) {
      testDatabaseIds = ids;
    } else if (TestDatabases.defaultIds) {
      testDatabaseIds = TestDatabases.defaultIds;
    } else {
      testDatabaseIds = Object.keys(allDatabases);
    }
    const supportedIds = testDatabaseIds.filter((id) => {
      const properties = allDatabases[id];
      if (!properties) {
        return false;
      }
      if (properties.connectionStringEnvironmentVariableName && process.env[properties.connectionStringEnvironmentVariableName]) {
        return true;
      }
      if (!properties.dockerImageName) {
        return true;
      }
      if (disableDocker) {
        return false;
      }
      return true;
    });
    const databases = new TestDatabases(supportedIds);
    if (supportedIds.length > 0) {
      afterAll(async () => {
        await databases.shutdown();
      });
    }
    return databases;
  }
  static setDefaults(options) {
    TestDatabases.defaultIds = options.ids;
  }
  constructor(supportedIds) {
    this.engineByTestDatabaseId = /* @__PURE__ */ new Map();
    this.supportedIds = supportedIds;
  }
  supports(id) {
    return this.supportedIds.includes(id);
  }
  eachSupportedId() {
    return this.supportedIds.map((id) => [id]);
  }
  /**
   * Returns a fresh, unique, empty logical database on an instance of the
   * given database ID platform.
   *
   * @param id - The ID of the database platform to use, e.g. 'POSTGRES_13'
   * @returns A `Knex` connection object
   */
  async init(id) {
    const properties = allDatabases[id];
    if (!properties) {
      const candidates = Object.keys(allDatabases).join(", ");
      throw new Error(
        `Unknown test database ${id}, possible values are ${candidates}`
      );
    }
    if (!this.supportedIds.includes(id)) {
      const candidates = this.supportedIds.join(", ");
      throw new Error(
        `Unsupported test database ${id} for this environment, possible values are ${candidates}`
      );
    }
    let engine = this.engineByTestDatabaseId.get(id);
    if (!engine) {
      const factory = this.engineFactoryByDriver[properties.driver];
      if (!factory) {
        throw new Error(`Unknown database driver ${properties.driver}`);
      }
      engine = await factory(properties);
      this.engineByTestDatabaseId.set(id, engine);
    }
    return await engine.createDatabaseInstance();
  }
  async shutdown() {
    const engines = [...this.engineByTestDatabaseId.values()];
    this.engineByTestDatabaseId.clear();
    for (const engine of engines) {
      try {
        await engine.shutdown();
      } catch (error) {
        console.warn(`TestDatabases: Failed to shutdown engine`, {
          engine,
          error
        });
      }
    }
  }
}

const tmpdirMarker = Symbol("os-tmpdir-mock");
class MockDirectoryImpl {
  #root;
  constructor(root) {
    this.#root = root;
  }
  get path() {
    return this.#root;
  }
  resolve(...paths) {
    return path.resolve(this.#root, ...paths);
  }
  setContent(root) {
    this.remove();
    return this.addContent(root);
  }
  addContent(root) {
    const entries = this.#transformInput(root);
    for (const entry of entries) {
      const fullPath = path.resolve(this.#root, entry.path);
      if (!backendPluginApi.isChildPath(this.#root, fullPath)) {
        throw new Error(
          `Provided path must resolve to a child path of the mock directory, got '${fullPath}'`
        );
      }
      if (entry.type === "dir") {
        fs__default.default.ensureDirSync(fullPath);
      } else if (entry.type === "file") {
        fs__default.default.ensureDirSync(path.dirname(fullPath));
        fs__default.default.writeFileSync(fullPath, entry.content);
      } else if (entry.type === "callback") {
        fs__default.default.ensureDirSync(path.dirname(fullPath));
        entry.callback({
          path: fullPath,
          symlink(target) {
            fs__default.default.symlinkSync(target, fullPath);
          }
        });
      }
    }
  }
  content(options) {
    const shouldReadAsText = (typeof options?.shouldReadAsText === "boolean" ? () => options?.shouldReadAsText : options?.shouldReadAsText) ?? ((path$1) => textextensions__default.default.includes(path.extname(path$1).slice(1)));
    const root = path.resolve(this.#root, options?.path ?? "");
    if (!backendPluginApi.isChildPath(this.#root, root)) {
      throw new Error(
        `Provided path must resolve to a child path of the mock directory, got '${root}'`
      );
    }
    function read(path$1) {
      if (!fs__default.default.pathExistsSync(path$1)) {
        return void 0;
      }
      const entries = fs__default.default.readdirSync(path$1, { withFileTypes: true });
      return Object.fromEntries(
        entries.map((entry) => {
          const fullPath = path.resolve(path$1, entry.name);
          if (entry.isDirectory()) {
            return [entry.name, read(fullPath)];
          }
          const content = fs__default.default.readFileSync(fullPath);
          const relativePosixPath = path.relative(root, fullPath).split(path.win32.sep).join(path.posix.sep);
          if (shouldReadAsText(relativePosixPath, content)) {
            return [entry.name, content.toString("utf8")];
          }
          return [entry.name, content];
        })
      );
    }
    return read(root);
  }
  clear = () => {
    this.setContent({});
  };
  remove = () => {
    fs__default.default.rmSync(this.#root, { recursive: true, force: true, maxRetries: 10 });
  };
  #transformInput(input) {
    const entries = [];
    function traverse(node, path) {
      if (typeof node === "string") {
        entries.push({
          type: "file",
          path,
          content: Buffer.from(node, "utf8")
        });
      } else if (node instanceof Buffer) {
        entries.push({ type: "file", path, content: node });
      } else if (typeof node === "function") {
        entries.push({ type: "callback", path, callback: node });
      } else {
        entries.push({ type: "dir", path });
        for (const [name, child] of Object.entries(node)) {
          traverse(child, path ? `${path}/${name}` : name);
        }
      }
    }
    traverse(input, "");
    return entries;
  }
}
function createMockDirectory(options) {
  const tmpDir = process.env.RUNNER_TEMP || os__default.default.tmpdir();
  const root = fs__default.default.mkdtempSync(path.join(tmpDir, "backstage-tmp-test-dir-"));
  const mocker = new MockDirectoryImpl(root);
  const origTmpdir = options?.mockOsTmpDir ? os__default.default.tmpdir : void 0;
  if (origTmpdir) {
    if (Object.hasOwn(origTmpdir, tmpdirMarker)) {
      throw new Error(
        "Cannot mock os.tmpdir() when it has already been mocked"
      );
    }
    const mock = Object.assign(() => mocker.path, { [tmpdirMarker]: true });
    os__default.default.tmpdir = mock;
  }
  const needsCleanup = !process.env.CI;
  if (needsCleanup) {
    process.on("beforeExit", mocker.remove);
  }
  try {
    afterAll(() => {
      if (origTmpdir) {
        os__default.default.tmpdir = origTmpdir;
      }
      if (needsCleanup) {
        mocker.remove();
      }
    });
  } catch {
  }
  if (options?.content) {
    mocker.setContent(options.content);
  }
  return mocker;
}

const DEFAULT_MOCK_USER_ENTITY_REF = "user:default/mock";
const DEFAULT_MOCK_SERVICE_SUBJECT = "external:test-service";
const MOCK_AUTH_COOKIE = "backstage-auth";
const MOCK_NONE_TOKEN = "mock-none-token";
const MOCK_USER_TOKEN = "mock-user-token";
const MOCK_USER_TOKEN_PREFIX = "mock-user-token:";
const MOCK_INVALID_USER_TOKEN = "mock-invalid-user-token";
const MOCK_USER_LIMITED_TOKEN_PREFIX = "mock-limited-user-token:";
const MOCK_INVALID_USER_LIMITED_TOKEN = "mock-invalid-limited-user-token";
const MOCK_SERVICE_TOKEN = "mock-service-token";
const MOCK_SERVICE_TOKEN_PREFIX = "mock-service-token:";
const MOCK_INVALID_SERVICE_TOKEN = "mock-invalid-service-token";
function validateUserEntityRef(ref) {
  if (!ref.match(/^.+:.+\/.+$/)) {
    throw new TypeError(
      `Invalid user entity reference '${ref}', expected <kind>:<namespace>/<name>`
    );
  }
}
exports.mockCredentials = void 0;
((mockCredentials2) => {
  function none() {
    return {
      $$type: "@backstage/BackstageCredentials",
      principal: { type: "none" }
    };
  }
  mockCredentials2.none = none;
  ((none2) => {
    function header() {
      return `Bearer ${MOCK_NONE_TOKEN}`;
    }
    none2.header = header;
  })(none = mockCredentials2.none || (mockCredentials2.none = {}));
  function user(userEntityRef = DEFAULT_MOCK_USER_ENTITY_REF) {
    validateUserEntityRef(userEntityRef);
    return {
      $$type: "@backstage/BackstageCredentials",
      principal: { type: "user", userEntityRef }
    };
  }
  mockCredentials2.user = user;
  ((user2) => {
    function token(userEntityRef) {
      if (userEntityRef) {
        validateUserEntityRef(userEntityRef);
        return `${MOCK_USER_TOKEN_PREFIX}${JSON.stringify({
          sub: userEntityRef
        })}`;
      }
      return MOCK_USER_TOKEN;
    }
    user2.token = token;
    function header(userEntityRef) {
      return `Bearer ${token(userEntityRef)}`;
    }
    user2.header = header;
    function invalidToken() {
      return MOCK_INVALID_USER_TOKEN;
    }
    user2.invalidToken = invalidToken;
    function invalidHeader() {
      return `Bearer ${invalidToken()}`;
    }
    user2.invalidHeader = invalidHeader;
  })(user = mockCredentials2.user || (mockCredentials2.user = {}));
  function limitedUser(userEntityRef = DEFAULT_MOCK_USER_ENTITY_REF) {
    return user(userEntityRef);
  }
  mockCredentials2.limitedUser = limitedUser;
  ((limitedUser2) => {
    function token(userEntityRef = DEFAULT_MOCK_USER_ENTITY_REF) {
      validateUserEntityRef(userEntityRef);
      return `${MOCK_USER_LIMITED_TOKEN_PREFIX}${JSON.stringify({
        sub: userEntityRef
      })}`;
    }
    limitedUser2.token = token;
    function cookie(userEntityRef) {
      return `${MOCK_AUTH_COOKIE}=${token(userEntityRef)}`;
    }
    limitedUser2.cookie = cookie;
    function invalidToken() {
      return MOCK_INVALID_USER_LIMITED_TOKEN;
    }
    limitedUser2.invalidToken = invalidToken;
    function invalidCookie() {
      return `${MOCK_AUTH_COOKIE}=${invalidToken()}`;
    }
    limitedUser2.invalidCookie = invalidCookie;
  })(limitedUser = mockCredentials2.limitedUser || (mockCredentials2.limitedUser = {}));
  function service(subject = DEFAULT_MOCK_SERVICE_SUBJECT, accessRestrictions) {
    return {
      $$type: "@backstage/BackstageCredentials",
      principal: {
        type: "service",
        subject,
        ...accessRestrictions ? { accessRestrictions } : {}
      }
    };
  }
  mockCredentials2.service = service;
  ((service2) => {
    function token(options) {
      if (options) {
        const { targetPluginId, onBehalfOf } = options;
        const oboPrincipal = onBehalfOf?.principal;
        const obo = oboPrincipal.type === "user" ? oboPrincipal.userEntityRef : void 0;
        const subject = oboPrincipal.type === "service" ? oboPrincipal.subject : void 0;
        return `${MOCK_SERVICE_TOKEN_PREFIX}${JSON.stringify({
          sub: subject,
          obo,
          target: targetPluginId
        })}`;
      }
      return MOCK_SERVICE_TOKEN;
    }
    service2.token = token;
    function header(options) {
      return `Bearer ${token(options)}`;
    }
    service2.header = header;
    function invalidToken() {
      return MOCK_INVALID_SERVICE_TOKEN;
    }
    service2.invalidToken = invalidToken;
    function invalidHeader() {
      return `Bearer ${invalidToken()}`;
    }
    service2.invalidHeader = invalidHeader;
  })(service = mockCredentials2.service || (mockCredentials2.service = {}));
})(exports.mockCredentials || (exports.mockCredentials = {}));

class MockAuthService {
  pluginId;
  disableDefaultAuthPolicy;
  constructor(options) {
    this.pluginId = options.pluginId;
    this.disableDefaultAuthPolicy = options.disableDefaultAuthPolicy;
  }
  async authenticate(token, options) {
    switch (token) {
      case MOCK_USER_TOKEN:
        return exports.mockCredentials.user();
      case MOCK_SERVICE_TOKEN:
        return exports.mockCredentials.service();
      case MOCK_INVALID_USER_TOKEN:
        throw new errors.AuthenticationError("User token is invalid");
      case MOCK_INVALID_USER_LIMITED_TOKEN:
        throw new errors.AuthenticationError("Limited user token is invalid");
      case MOCK_INVALID_SERVICE_TOKEN:
        throw new errors.AuthenticationError("Service token is invalid");
      case "":
        throw new errors.AuthenticationError("Token is empty");
    }
    if (token.startsWith(MOCK_USER_TOKEN_PREFIX)) {
      const { sub: userEntityRef } = JSON.parse(
        token.slice(MOCK_USER_TOKEN_PREFIX.length)
      );
      return exports.mockCredentials.user(userEntityRef);
    }
    if (token.startsWith(MOCK_USER_LIMITED_TOKEN_PREFIX)) {
      if (!options?.allowLimitedAccess) {
        throw new errors.AuthenticationError("Limited user token is not allowed");
      }
      const { sub: userEntityRef } = JSON.parse(
        token.slice(MOCK_USER_LIMITED_TOKEN_PREFIX.length)
      );
      return exports.mockCredentials.user(userEntityRef);
    }
    if (token.startsWith(MOCK_SERVICE_TOKEN_PREFIX)) {
      const { sub, target, obo } = JSON.parse(
        token.slice(MOCK_SERVICE_TOKEN_PREFIX.length)
      );
      if (target && target !== this.pluginId) {
        throw new errors.AuthenticationError(
          `Invalid mock token target plugin ID, got '${target}' but expected '${this.pluginId}'`
        );
      }
      if (obo) {
        return exports.mockCredentials.user(obo);
      }
      return exports.mockCredentials.service(sub);
    }
    throw new errors.AuthenticationError(`Unknown mock token '${token}'`);
  }
  async getNoneCredentials() {
    return exports.mockCredentials.none();
  }
  async getOwnServiceCredentials() {
    return exports.mockCredentials.service(`plugin:${this.pluginId}`);
  }
  isPrincipal(credentials, type) {
    const principal = credentials.principal;
    if (type === "unknown") {
      return true;
    }
    if (principal.type !== type) {
      return false;
    }
    return true;
  }
  async getPluginRequestToken(options) {
    const principal = options.onBehalfOf.principal;
    if (principal.type === "none" && this.disableDefaultAuthPolicy) {
      return { token: "" };
    }
    if (principal.type !== "user" && principal.type !== "service") {
      throw new errors.AuthenticationError(
        `Refused to issue service token for credential type '${principal.type}'`
      );
    }
    return {
      token: exports.mockCredentials.service.token({
        onBehalfOf: options.onBehalfOf,
        targetPluginId: options.targetPluginId
      })
    };
  }
  async getLimitedUserToken(credentials) {
    if (credentials.principal.type !== "user") {
      throw new errors.AuthenticationError(
        `Refused to issue limited user token for credential type '${credentials.principal.type}'`
      );
    }
    return {
      token: exports.mockCredentials.limitedUser.token(
        credentials.principal.userEntityRef
      ),
      expiresAt: new Date(Date.now() + 36e5)
    };
  }
  listPublicServiceKeys() {
    throw new Error("Not implemented");
  }
}

class MockHttpAuthService {
  #auth;
  #defaultCredentials;
  constructor(pluginId, defaultCredentials) {
    this.#auth = new MockAuthService({
      pluginId,
      disableDefaultAuthPolicy: false
    });
    this.#defaultCredentials = defaultCredentials;
  }
  async #getCredentials(req, allowLimitedAccess) {
    const header = req.headers.authorization;
    const token = typeof header === "string" ? header.match(/^Bearer[ ]+(\S+)$/i)?.[1] : void 0;
    if (token) {
      if (token === MOCK_NONE_TOKEN) {
        return this.#auth.getNoneCredentials();
      }
      return await this.#auth.authenticate(token, {
        allowLimitedAccess
      });
    }
    if (allowLimitedAccess) {
      const cookieHeader = req.headers.cookie;
      if (cookieHeader) {
        const cookies = cookie.parse(cookieHeader);
        const cookie$1 = cookies[MOCK_AUTH_COOKIE];
        if (cookie$1) {
          return await this.#auth.authenticate(cookie$1, {
            allowLimitedAccess: true
          });
        }
      }
    }
    return this.#defaultCredentials;
  }
  async credentials(req, options) {
    const credentials = await this.#getCredentials(
      req,
      options?.allowLimitedAccess ?? false
    );
    const allowedPrincipalTypes = options?.allow;
    if (!allowedPrincipalTypes) {
      return credentials;
    }
    if (this.#auth.isPrincipal(credentials, "none")) {
      if (allowedPrincipalTypes.includes("none")) {
        return credentials;
      }
      throw new errors.AuthenticationError("Missing credentials");
    } else if (this.#auth.isPrincipal(credentials, "user")) {
      if (allowedPrincipalTypes.includes("user")) {
        return credentials;
      }
      throw new errors.NotAllowedError(
        `This endpoint does not allow 'user' credentials`
      );
    } else if (this.#auth.isPrincipal(credentials, "service")) {
      if (allowedPrincipalTypes.includes("service")) {
        return credentials;
      }
      throw new errors.NotAllowedError(
        `This endpoint does not allow 'service' credentials`
      );
    }
    throw new errors.NotAllowedError(
      "Unknown principal type, this should never happen"
    );
  }
  async issueUserCookie(res, options) {
    const credentials = options?.credentials ?? await this.credentials(res.req, { allow: ["user"] });
    res.setHeader(
      "Set-Cookie",
      exports.mockCredentials.limitedUser.cookie(credentials.principal.userEntityRef)
    );
    return { expiresAt: new Date(Date.now() + 36e5) };
  }
}

class MockIdentityService {
  getIdentity(_options) {
    return Promise.resolve({
      token: "mock-token",
      identity: {
        type: "user",
        userEntityRef: "user:default/mock-user",
        ownershipEntityRefs: []
      }
    });
  }
}

const levels = {
  none: 0,
  error: 1,
  warn: 2,
  info: 3,
  debug: 4
};
class MockRootLoggerService {
  #level;
  #meta;
  static create(options) {
    const level = options?.level ?? "none";
    if (!(level in levels)) {
      throw new Error(`Invalid log level '${level}'`);
    }
    return new MockRootLoggerService(levels[level], {});
  }
  error(message, meta) {
    this.#log("error", message, meta);
  }
  warn(message, meta) {
    this.#log("warn", message, meta);
  }
  info(message, meta) {
    this.#log("info", message, meta);
  }
  debug(message, meta) {
    this.#log("debug", message, meta);
  }
  child(meta) {
    return new MockRootLoggerService(this.#level, { ...this.#meta, ...meta });
  }
  constructor(level, meta) {
    this.#level = level;
    this.#meta = meta;
  }
  #log(level, message, meta) {
    const levelValue = levels[level] ?? 0;
    if (levelValue <= this.#level) {
      const labels = Object.entries(this.#meta).map(([key, value]) => `${key}=${value}`).join(",");
      console[level](`${labels} ${message}`, meta);
    }
  }
}

class MockUserInfoService {
  customInfo;
  constructor(customInfo) {
    this.customInfo = customInfo ?? {};
  }
  async getUserInfo(credentials) {
    const principal = credentials.principal;
    if (principal.type !== "user") {
      throw new errors.InputError(
        `User info not available for principal type '${principal.type}'`
      );
    }
    return {
      userEntityRef: principal.userEntityRef,
      ownershipEntityRefs: [principal.userEntityRef],
      ...this.customInfo
    };
  }
}

function createLoggerMock() {
  return {
    child: jest.fn().mockImplementation(createLoggerMock),
    debug: jest.fn(),
    error: jest.fn(),
    info: jest.fn(),
    warn: jest.fn()
  };
}
function simpleFactoryWithOptions(ref, factory) {
  const factoryWithOptions = (...options) => backendPluginApi.createServiceFactory({
    service: ref,
    deps: {},
    async factory() {
      return factory(...options);
    }
  })();
  return Object.assign(
    factoryWithOptions,
    factoryWithOptions(...[void 0])
  );
}
function simpleMock(ref, mockFactory) {
  return (partialImpl) => {
    const mock = mockFactory();
    if (partialImpl) {
      for (const [key, impl] of Object.entries(partialImpl)) {
        if (typeof impl === "function") {
          mock[key].mockImplementation(impl);
        } else {
          mock[key] = impl;
        }
      }
    }
    return Object.assign(mock, {
      factory: backendPluginApi.createServiceFactory({
        service: ref,
        deps: {},
        factory: () => mock
      })()
    });
  };
}
exports.mockServices = void 0;
((mockServices2) => {
  function rootConfig(options) {
    return new config.ConfigReader(options?.data, "mock-config");
  }
  mockServices2.rootConfig = rootConfig;
  ((rootConfig2) => {
    rootConfig2.factory = simpleFactoryWithOptions(
      backendPluginApi.coreServices.rootConfig,
      rootConfig2
    );
  })(rootConfig = mockServices2.rootConfig || (mockServices2.rootConfig = {}));
  function rootLogger(options) {
    return MockRootLoggerService.create(options);
  }
  mockServices2.rootLogger = rootLogger;
  ((rootLogger2) => {
    rootLogger2.factory = simpleFactoryWithOptions(
      backendPluginApi.coreServices.rootLogger,
      rootLogger2
    );
    rootLogger2.mock = simpleMock(backendPluginApi.coreServices.rootLogger, () => ({
      child: jest.fn(),
      debug: jest.fn(),
      error: jest.fn(),
      info: jest.fn(),
      warn: jest.fn()
    }));
  })(rootLogger = mockServices2.rootLogger || (mockServices2.rootLogger = {}));
  function tokenManager() {
    return {
      async getToken() {
        return { token: "mock-token" };
      },
      async authenticate(token) {
        if (token !== "mock-token") {
          throw new Error("Invalid token");
        }
      }
    };
  }
  mockServices2.tokenManager = tokenManager;
  ((tokenManager2) => {
    tokenManager2.factory = backendPluginApi.createServiceFactory({
      service: backendPluginApi.coreServices.tokenManager,
      deps: {},
      factory: () => tokenManager2()
    });
    tokenManager2.mock = simpleMock(backendPluginApi.coreServices.tokenManager, () => ({
      authenticate: jest.fn(),
      getToken: jest.fn()
    }));
  })(tokenManager = mockServices2.tokenManager || (mockServices2.tokenManager = {}));
  function identity() {
    return new MockIdentityService();
  }
  mockServices2.identity = identity;
  ((identity2) => {
    identity2.factory = backendPluginApi.createServiceFactory({
      service: backendPluginApi.coreServices.identity,
      deps: {},
      factory: () => identity2()
    });
    identity2.mock = simpleMock(backendPluginApi.coreServices.identity, () => ({
      getIdentity: jest.fn()
    }));
  })(identity = mockServices2.identity || (mockServices2.identity = {}));
  function auth(options) {
    return new MockAuthService({
      pluginId: options?.pluginId ?? "test",
      disableDefaultAuthPolicy: Boolean(options?.disableDefaultAuthPolicy)
    });
  }
  mockServices2.auth = auth;
  ((auth2) => {
    auth2.factory = backendPluginApi.createServiceFactory({
      service: backendPluginApi.coreServices.auth,
      deps: {
        plugin: backendPluginApi.coreServices.pluginMetadata,
        config: backendPluginApi.coreServices.rootConfig
      },
      factory({ plugin, config }) {
        const disableDefaultAuthPolicy = Boolean(
          config.getOptionalBoolean(
            "backend.auth.dangerouslyDisableDefaultAuthPolicy"
          )
        );
        return new MockAuthService({
          pluginId: plugin.getId(),
          disableDefaultAuthPolicy
        });
      }
    });
    auth2.mock = simpleMock(backendPluginApi.coreServices.auth, () => ({
      authenticate: jest.fn(),
      getNoneCredentials: jest.fn(),
      getOwnServiceCredentials: jest.fn(),
      isPrincipal: jest.fn(),
      getPluginRequestToken: jest.fn(),
      getLimitedUserToken: jest.fn(),
      listPublicServiceKeys: jest.fn()
    }));
  })(auth = mockServices2.auth || (mockServices2.auth = {}));
  function discovery$1() {
    return discovery.HostDiscovery.fromConfig(
      new config.ConfigReader({
        backend: {
          // Invalid port to make sure that requests are always mocked
          baseUrl: "http://localhost:0",
          listen: { port: 0 }
        }
      })
    );
  }
  mockServices2.discovery = discovery$1;
  ((discovery2) => {
    discovery2.factory = discovery.discoveryServiceFactory;
    discovery2.mock = simpleMock(backendPluginApi.coreServices.discovery, () => ({
      getBaseUrl: jest.fn(),
      getExternalBaseUrl: jest.fn()
    }));
  })(discovery$1 = mockServices2.discovery || (mockServices2.discovery = {}));
  function httpAuth(options) {
    return new MockHttpAuthService(
      options?.pluginId ?? "test",
      options?.defaultCredentials ?? exports.mockCredentials.user()
    );
  }
  mockServices2.httpAuth = httpAuth;
  ((httpAuth2) => {
    const factoryWithOptions = (options) => backendPluginApi.createServiceFactory({
      service: backendPluginApi.coreServices.httpAuth,
      deps: { plugin: backendPluginApi.coreServices.pluginMetadata },
      factory: ({ plugin }) => new MockHttpAuthService(
        plugin.getId(),
        options?.defaultCredentials ?? exports.mockCredentials.user()
      )
    })();
    httpAuth2.factory = Object.assign(
      factoryWithOptions,
      factoryWithOptions()
    );
    httpAuth2.mock = simpleMock(backendPluginApi.coreServices.httpAuth, () => ({
      credentials: jest.fn(),
      issueUserCookie: jest.fn()
    }));
  })(httpAuth = mockServices2.httpAuth || (mockServices2.httpAuth = {}));
  function userInfo(customInfo) {
    return new MockUserInfoService(customInfo);
  }
  mockServices2.userInfo = userInfo;
  ((userInfo2) => {
    userInfo2.factory = backendPluginApi.createServiceFactory({
      service: backendPluginApi.coreServices.userInfo,
      deps: {},
      factory() {
        return new MockUserInfoService();
      }
    });
    userInfo2.mock = simpleMock(backendPluginApi.coreServices.userInfo, () => ({
      getUserInfo: jest.fn()
    }));
  })(userInfo = mockServices2.userInfo || (mockServices2.userInfo = {}));
  ((cache2) => {
    cache2.factory = cache.cacheServiceFactory;
    cache2.mock = simpleMock(backendPluginApi.coreServices.cache, () => ({
      delete: jest.fn(),
      get: jest.fn(),
      set: jest.fn(),
      withOptions: jest.fn()
    }));
  })(mockServices2.cache || (mockServices2.cache = {}));
  ((database2) => {
    database2.factory = database.databaseServiceFactory;
    database2.mock = simpleMock(backendPluginApi.coreServices.database, () => ({
      getClient: jest.fn()
    }));
  })(mockServices2.database || (mockServices2.database = {}));
  ((rootHealth2) => {
    rootHealth2.factory = rootHealth.rootHealthServiceFactory;
    rootHealth2.mock = simpleMock(backendPluginApi.coreServices.rootHealth, () => ({
      getLiveness: jest.fn(),
      getReadiness: jest.fn()
    }));
  })(mockServices2.rootHealth || (mockServices2.rootHealth = {}));
  ((httpRouter2) => {
    httpRouter2.factory = httpRouter.httpRouterServiceFactory;
    httpRouter2.mock = simpleMock(backendPluginApi.coreServices.httpRouter, () => ({
      use: jest.fn(),
      addAuthPolicy: jest.fn()
    }));
  })(mockServices2.httpRouter || (mockServices2.httpRouter = {}));
  ((rootHttpRouter2) => {
    rootHttpRouter2.factory = rootHttpRouter.rootHttpRouterServiceFactory;
    rootHttpRouter2.mock = simpleMock(backendPluginApi.coreServices.rootHttpRouter, () => ({
      use: jest.fn()
    }));
  })(mockServices2.rootHttpRouter || (mockServices2.rootHttpRouter = {}));
  ((lifecycle2) => {
    lifecycle2.factory = lifecycle.lifecycleServiceFactory;
    lifecycle2.mock = simpleMock(backendPluginApi.coreServices.lifecycle, () => ({
      addShutdownHook: jest.fn(),
      addStartupHook: jest.fn()
    }));
  })(mockServices2.lifecycle || (mockServices2.lifecycle = {}));
  ((logger2) => {
    logger2.factory = logger.loggerServiceFactory;
    logger2.mock = simpleMock(
      backendPluginApi.coreServices.logger,
      () => createLoggerMock()
    );
  })(mockServices2.logger || (mockServices2.logger = {}));
  ((permissions2) => {
    permissions2.factory = permissions.permissionsServiceFactory;
    permissions2.mock = simpleMock(backendPluginApi.coreServices.permissions, () => ({
      authorize: jest.fn(),
      authorizeConditional: jest.fn()
    }));
  })(mockServices2.permissions || (mockServices2.permissions = {}));
  ((rootLifecycle2) => {
    rootLifecycle2.factory = rootLifecycle.rootLifecycleServiceFactory;
    rootLifecycle2.mock = simpleMock(backendPluginApi.coreServices.rootLifecycle, () => ({
      addShutdownHook: jest.fn(),
      addStartupHook: jest.fn()
    }));
  })(mockServices2.rootLifecycle || (mockServices2.rootLifecycle = {}));
  ((scheduler2) => {
    scheduler2.factory = scheduler.schedulerServiceFactory;
    scheduler2.mock = simpleMock(backendPluginApi.coreServices.scheduler, () => ({
      createScheduledTaskRunner: jest.fn(),
      getScheduledTasks: jest.fn(),
      scheduleTask: jest.fn(),
      triggerTask: jest.fn()
    }));
  })(mockServices2.scheduler || (mockServices2.scheduler = {}));
  ((urlReader2) => {
    urlReader2.factory = urlReader.urlReaderServiceFactory;
    urlReader2.mock = simpleMock(backendPluginApi.coreServices.urlReader, () => ({
      readTree: jest.fn(),
      readUrl: jest.fn(),
      search: jest.fn()
    }));
  })(mockServices2.urlReader || (mockServices2.urlReader = {}));
  ((events2) => {
    events2.factory = pluginEventsNode.eventsServiceFactory;
    events2.mock = simpleMock(pluginEventsNode.eventsServiceRef, () => ({
      publish: jest.fn(),
      subscribe: jest.fn()
    }));
  })(mockServices2.events || (mockServices2.events = {}));
})(exports.mockServices || (exports.mockServices = {}));

const defaultServiceFactories = [
  exports.mockServices.auth.factory(),
  exports.mockServices.cache.factory(),
  exports.mockServices.rootConfig.factory(),
  exports.mockServices.database.factory(),
  exports.mockServices.httpAuth.factory(),
  exports.mockServices.httpRouter.factory(),
  exports.mockServices.identity.factory(),
  exports.mockServices.lifecycle.factory(),
  exports.mockServices.logger.factory(),
  exports.mockServices.permissions.factory(),
  exports.mockServices.rootLifecycle.factory(),
  exports.mockServices.rootLogger.factory(),
  exports.mockServices.scheduler.factory(),
  exports.mockServices.tokenManager.factory(),
  exports.mockServices.userInfo.factory(),
  exports.mockServices.urlReader.factory(),
  exports.mockServices.events.factory()
];
function createPluginsForOrphanModules(features) {
  const pluginIds = /* @__PURE__ */ new Set();
  const modulePluginIds = /* @__PURE__ */ new Set();
  for (const feature of features) {
    if (isInternalBackendFeature(feature)) {
      const registrations = feature.getRegistrations();
      for (const registration of registrations) {
        if (registration.type === "plugin") {
          pluginIds.add(registration.pluginId);
        } else if (registration.type === "module") {
          modulePluginIds.add(registration.pluginId);
        }
      }
    }
  }
  for (const pluginId of pluginIds) {
    modulePluginIds.delete(pluginId);
  }
  return Array.from(modulePluginIds).map(
    (pluginId) => backendPluginApi.createBackendPlugin({
      pluginId,
      register(reg) {
        reg.registerInit({ deps: {}, async init() {
        } });
      }
    })
  );
}
function createExtensionPointTestModules(features, extensionPointTuples) {
  if (!extensionPointTuples) {
    return [];
  }
  const registrations = features.flatMap((feature) => {
    if (feature.$$type !== "@backstage/BackendFeature") {
      throw new Error(
        `Failed to add feature, invalid type '${feature.$$type}'`
      );
    }
    if (isInternalBackendFeature(feature)) {
      if (feature.version !== "v1") {
        throw new Error(
          `Failed to add feature, invalid version '${feature.version}'`
        );
      }
      return feature.getRegistrations();
    }
    return [];
  });
  const extensionPointMap = new Map(
    extensionPointTuples.map((ep) => [ep[0].id, ep])
  );
  const extensionPointsToSort = new Set(extensionPointMap.keys());
  const extensionPointsByPlugin = /* @__PURE__ */ new Map();
  for (const registration of registrations) {
    if (registration.type === "module") {
      const testDep = Object.values(registration.init.deps).filter(
        (dep) => extensionPointsToSort.has(dep.id)
      );
      if (testDep.length > 0) {
        let points = extensionPointsByPlugin.get(registration.pluginId);
        if (!points) {
          points = [];
          extensionPointsByPlugin.set(registration.pluginId, points);
        }
        for (const { id } of testDep) {
          points.push(id);
          extensionPointsToSort.delete(id);
        }
      }
    }
  }
  if (extensionPointsToSort.size > 0) {
    const list = Array.from(extensionPointsToSort).map((id) => `'${id}'`).join(", ");
    throw new Error(
      `Unable to determine the plugin ID of extension point(s) ${list}. Tested extension points must be depended on by one or more tested modules.`
    );
  }
  const modules = [];
  for (const [pluginId, pluginExtensionPointIds] of extensionPointsByPlugin) {
    modules.push(
      backendPluginApi.createBackendModule({
        pluginId,
        moduleId: "test-extension-point-registration",
        register(reg) {
          for (const id of pluginExtensionPointIds) {
            const tuple = extensionPointMap.get(id);
            reg.registerExtensionPoint(...tuple);
          }
          reg.registerInit({ deps: {}, async init() {
          } });
        }
      })
    );
  }
  return modules;
}
function isPromise(value) {
  return typeof value === "object" && value !== null && "then" in value && typeof value.then === "function";
}
function unwrapFeature(feature) {
  return typeof feature === "function" ? feature() : feature;
}
const backendInstancesToCleanUp = new Array();
async function startTestBackend(options) {
  const { extensionPoints, ...otherOptions } = options;
  const features = await Promise.all(
    options.features?.map(async (val) => {
      if (isPromise(val)) {
        const { default: feature } = await val;
        return unwrapFeature(feature);
      }
      return unwrapFeature(val);
    }) ?? []
  );
  let server;
  const rootHttpRouterFactory = backendPluginApi.createServiceFactory({
    service: backendPluginApi.coreServices.rootHttpRouter,
    deps: {
      config: backendPluginApi.coreServices.rootConfig,
      lifecycle: backendPluginApi.coreServices.rootLifecycle,
      rootLogger: backendPluginApi.coreServices.rootLogger
    },
    async factory({ config, lifecycle, rootLogger }) {
      const router = backendAppApi.DefaultRootHttpRouter.create();
      const logger = rootLogger.child({ service: "rootHttpRouter" });
      const app = express__default.default();
      const middleware = backendAppApi.MiddlewareFactory.create({ config, logger });
      app.use(router.handler());
      app.use(middleware.notFound());
      app.use(middleware.error());
      server = await backendAppApi.createHttpServer(
        app,
        { listen: { host: "", port: 0 } },
        { logger }
      );
      lifecycle.addShutdownHook(() => server.stop(), { logger });
      await server.start();
      return router;
    }
  });
  const discoveryFactory = backendPluginApi.createServiceFactory({
    service: backendPluginApi.coreServices.discovery,
    deps: {
      rootHttpRouter: backendPluginApi.coreServices.rootHttpRouter
    },
    async factory() {
      if (!server) {
        throw new Error("Test server not started yet");
      }
      const port = server.port();
      const discovery = backendAppApi.HostDiscovery.fromConfig(
        new config.ConfigReader({
          backend: { baseUrl: `http://localhost:${port}`, listen: { port } }
        })
      );
      return discovery;
    }
  });
  const backend = backendAppApi.createSpecializedBackend({
    ...otherOptions,
    defaultServiceFactories: [
      ...defaultServiceFactories,
      rootHttpRouterFactory,
      discoveryFactory
    ]
  });
  backendInstancesToCleanUp.push(backend);
  for (const m of createExtensionPointTestModules(features, extensionPoints)) {
    backend.add(m);
  }
  for (const p of createPluginsForOrphanModules(features)) {
    backend.add(p);
  }
  for (const feature of features) {
    backend.add(feature);
  }
  await backend.start();
  return Object.assign(backend, {
    get server() {
      if (!server) {
        throw new Error("TestBackend server is not available");
      }
      return server;
    }
  });
}
let registered = false;
function registerTestHooks() {
  if (typeof afterAll !== "function") {
    return;
  }
  if (registered) {
    return;
  }
  registered = true;
  afterAll(async () => {
    await Promise.all(
      backendInstancesToCleanUp.map(async (backend) => {
        try {
          await backend.stop();
        } catch (error) {
          console.error(`Failed to stop backend after tests, ${error}`);
        }
      })
    );
    backendInstancesToCleanUp.length = 0;
  });
}
registerTestHooks();
function isInternalBackendFeature(feature) {
  return typeof feature.getRegistrations === "function";
}

class Node {
  constructor(value, consumes, provides) {
    this.value = value;
    this.consumes = consumes;
    this.provides = provides;
  }
  static from(input) {
    return new Node(
      input.value,
      input.consumes ? new Set(input.consumes) : /* @__PURE__ */ new Set(),
      input.provides ? new Set(input.provides) : /* @__PURE__ */ new Set()
    );
  }
}
class CycleKeySet {
  static from(nodes) {
    return new CycleKeySet(nodes);
  }
  #nodeIds;
  #cycleKeys;
  constructor(nodes) {
    this.#nodeIds = new Map(nodes.map((n, i) => [n.value, i]));
    this.#cycleKeys = /* @__PURE__ */ new Set();
  }
  tryAdd(path) {
    const cycleKey = this.#getCycleKey(path);
    if (this.#cycleKeys.has(cycleKey)) {
      return false;
    }
    this.#cycleKeys.add(cycleKey);
    return true;
  }
  #getCycleKey(path) {
    return path.map((n) => this.#nodeIds.get(n)).sort().join(",");
  }
}
class DependencyGraph {
  static fromMap(nodes) {
    return this.fromIterable(
      Object.entries(nodes).map(([key, node]) => ({
        value: String(key),
        ...node
      }))
    );
  }
  static fromIterable(nodeInputs) {
    const nodes = new Array();
    for (const nodeInput of nodeInputs) {
      nodes.push(Node.from(nodeInput));
    }
    return new DependencyGraph(nodes);
  }
  #nodes;
  #allProvided;
  constructor(nodes) {
    this.#nodes = nodes;
    this.#allProvided = /* @__PURE__ */ new Set();
    for (const node of this.#nodes.values()) {
      for (const produced of node.provides) {
        this.#allProvided.add(produced);
      }
    }
  }
  /**
   * Find all nodes that consume dependencies that are not provided by any other node.
   */
  findUnsatisfiedDeps() {
    const unsatisfiedDependencies = [];
    for (const node of this.#nodes.values()) {
      const unsatisfied = Array.from(node.consumes).filter(
        (id) => !this.#allProvided.has(id)
      );
      if (unsatisfied.length > 0) {
        unsatisfiedDependencies.push({ value: node.value, unsatisfied });
      }
    }
    return unsatisfiedDependencies;
  }
  /**
   * Detect the first circular dependency within the graph, returning the path of nodes that
   * form a cycle, with the same node as the first and last element of the array.
   */
  detectCircularDependency() {
    return this.detectCircularDependencies().next().value;
  }
  /**
   * Detect circular dependencies within the graph, returning the path of nodes that
   * form a cycle, with the same node as the first and last element of the array.
   */
  *detectCircularDependencies() {
    const cycleKeys = CycleKeySet.from(this.#nodes);
    for (const startNode of this.#nodes) {
      const visited = /* @__PURE__ */ new Set();
      const stack = new Array([
        startNode,
        [startNode.value]
      ]);
      while (stack.length > 0) {
        const [node, path] = stack.pop();
        if (visited.has(node)) {
          continue;
        }
        visited.add(node);
        for (const consumed of node.consumes) {
          const providerNodes = this.#nodes.filter(
            (other) => other.provides.has(consumed)
          );
          for (const provider of providerNodes) {
            if (provider === startNode) {
              if (cycleKeys.tryAdd(path)) {
                yield [...path, startNode.value];
              }
              break;
            }
            if (!visited.has(provider)) {
              stack.push([provider, [...path, provider.value]]);
            }
          }
        }
      }
    }
    return void 0;
  }
  /**
   * Traverses the dependency graph in topological order, calling the provided
   * function for each node and waiting for it to resolve.
   *
   * The nodes are traversed in parallel, but in such a way that no node is
   * visited before all of its dependencies.
   *
   * Dependencies of nodes that are not produced by any other nodes will be ignored.
   */
  async parallelTopologicalTraversal(fn) {
    const allProvided = this.#allProvided;
    const producedSoFar = /* @__PURE__ */ new Set();
    const waiting = new Set(this.#nodes.values());
    const visited = /* @__PURE__ */ new Set();
    const results = new Array();
    let inFlight = 0;
    async function processMoreNodes() {
      if (waiting.size === 0) {
        return;
      }
      const nodesToProcess = [];
      for (const node of waiting) {
        let ready = true;
        for (const consumed of node.consumes) {
          if (allProvided.has(consumed) && !producedSoFar.has(consumed)) {
            ready = false;
            continue;
          }
        }
        if (ready) {
          nodesToProcess.push(node);
        }
      }
      for (const node of nodesToProcess) {
        waiting.delete(node);
      }
      if (nodesToProcess.length === 0 && inFlight === 0) {
        throw new Error("Circular dependency detected");
      }
      await Promise.all(nodesToProcess.map(processNode));
    }
    async function processNode(node) {
      visited.add(node);
      inFlight += 1;
      const result = await fn(node.value);
      results.push(result);
      node.provides.forEach((produced) => producedSoFar.add(produced));
      inFlight -= 1;
      await processMoreNodes();
    }
    await processMoreNodes();
    return results;
  }
}

function toInternalServiceFactory(factory) {
  const f = factory;
  if (f.$$type !== "@backstage/BackendFeature") {
    throw new Error(`Invalid service factory, bad type '${f.$$type}'`);
  }
  if (f.version !== "v1") {
    throw new Error(`Invalid service factory, bad version '${f.version}'`);
  }
  return f;
}
function createPluginMetadataServiceFactory(pluginId) {
  return backendPluginApi.createServiceFactory({
    service: backendPluginApi.coreServices.pluginMetadata,
    deps: {},
    factory: async () => ({ getId: () => pluginId })
  });
}
class ServiceRegistry {
  static create(factories) {
    const registry = new ServiceRegistry(factories);
    registry.checkForCircularDeps();
    return registry;
  }
  #providedFactories;
  #loadedDefaultFactories;
  #implementations;
  #rootServiceImplementations = /* @__PURE__ */ new Map();
  #addedFactoryIds = /* @__PURE__ */ new Set();
  #instantiatedFactories = /* @__PURE__ */ new Set();
  constructor(factories) {
    this.#providedFactories = new Map(
      factories.map((sf) => [sf.service.id, toInternalServiceFactory(sf)])
    );
    this.#loadedDefaultFactories = /* @__PURE__ */ new Map();
    this.#implementations = /* @__PURE__ */ new Map();
  }
  #resolveFactory(ref, pluginId) {
    if (ref.id === backendPluginApi.coreServices.pluginMetadata.id) {
      return Promise.resolve(
        toInternalServiceFactory(createPluginMetadataServiceFactory(pluginId))
      );
    }
    let resolvedFactory = this.#providedFactories.get(ref.id);
    const { __defaultFactory: defaultFactory } = ref;
    if (!resolvedFactory && !defaultFactory) {
      return void 0;
    }
    if (!resolvedFactory) {
      let loadedFactory = this.#loadedDefaultFactories.get(defaultFactory);
      if (!loadedFactory) {
        loadedFactory = Promise.resolve().then(() => defaultFactory(ref)).then(
          (f) => toInternalServiceFactory(typeof f === "function" ? f() : f)
        );
        this.#loadedDefaultFactories.set(defaultFactory, loadedFactory);
      }
      resolvedFactory = loadedFactory.catch((error) => {
        throw new Error(
          `Failed to instantiate service '${ref.id}' because the default factory loader threw an error, ${errors.stringifyError(
            error
          )}`
        );
      });
    }
    return Promise.resolve(resolvedFactory);
  }
  #checkForMissingDeps(factory, pluginId) {
    const missingDeps = Object.values(factory.deps).filter((ref) => {
      if (ref.id === backendPluginApi.coreServices.pluginMetadata.id) {
        return false;
      }
      if (this.#providedFactories.get(ref.id)) {
        return false;
      }
      return !ref.__defaultFactory;
    });
    if (missingDeps.length) {
      const missing = missingDeps.map((r) => `'${r.id}'`).join(", ");
      throw new Error(
        `Failed to instantiate service '${factory.service.id}' for '${pluginId}' because the following dependent services are missing: ${missing}`
      );
    }
  }
  checkForCircularDeps() {
    const graph = DependencyGraph.fromIterable(
      Array.from(this.#providedFactories).map(
        ([serviceId, serviceFactory]) => ({
          value: serviceId,
          provides: [serviceId],
          consumes: Object.values(serviceFactory.deps).map((d) => d.id)
        })
      )
    );
    const circularDependencies = Array.from(graph.detectCircularDependencies());
    if (circularDependencies.length) {
      const cycles = circularDependencies.map((c) => c.map((id) => `'${id}'`).join(" -> ")).join("\n  ");
      throw new errors.ConflictError(`Circular dependencies detected:
  ${cycles}`);
    }
  }
  add(factory) {
    const factoryId = factory.service.id;
    if (factoryId === backendPluginApi.coreServices.pluginMetadata.id) {
      throw new Error(
        `The ${backendPluginApi.coreServices.pluginMetadata.id} service cannot be overridden`
      );
    }
    if (this.#addedFactoryIds.has(factoryId)) {
      throw new Error(
        `Duplicate service implementations provided for ${factoryId}`
      );
    }
    if (this.#instantiatedFactories.has(factoryId)) {
      throw new Error(
        `Unable to set service factory with id ${factoryId}, service has already been instantiated`
      );
    }
    this.#addedFactoryIds.add(factoryId);
    this.#providedFactories.set(factoryId, toInternalServiceFactory(factory));
  }
  async initializeEagerServicesWithScope(scope, pluginId = "root") {
    for (const factory of this.#providedFactories.values()) {
      if (factory.service.scope === scope) {
        if (scope === "root" && factory.initialization !== "lazy") {
          await this.get(factory.service, pluginId);
        } else if (scope === "plugin" && factory.initialization === "always") {
          await this.get(factory.service, pluginId);
        }
      }
    }
  }
  get(ref, pluginId) {
    this.#instantiatedFactories.add(ref.id);
    return this.#resolveFactory(ref, pluginId)?.then((factory) => {
      if (factory.service.scope === "root") {
        let existing = this.#rootServiceImplementations.get(factory);
        if (!existing) {
          this.#checkForMissingDeps(factory, pluginId);
          const rootDeps = new Array();
          for (const [name, serviceRef] of Object.entries(factory.deps)) {
            if (serviceRef.scope !== "root") {
              throw new Error(
                `Failed to instantiate 'root' scoped service '${ref.id}' because it depends on '${serviceRef.scope}' scoped service '${serviceRef.id}'.`
              );
            }
            const target = this.get(serviceRef, pluginId);
            rootDeps.push(target.then((impl) => [name, impl]));
          }
          existing = Promise.all(rootDeps).then(
            (entries) => factory.factory(Object.fromEntries(entries), void 0)
          );
          this.#rootServiceImplementations.set(factory, existing);
        }
        return existing;
      }
      let implementation = this.#implementations.get(factory);
      if (!implementation) {
        this.#checkForMissingDeps(factory, pluginId);
        const rootDeps = new Array();
        for (const [name, serviceRef] of Object.entries(factory.deps)) {
          if (serviceRef.scope === "root") {
            const target = this.get(serviceRef, pluginId);
            rootDeps.push(target.then((impl) => [name, impl]));
          }
        }
        implementation = {
          context: Promise.all(rootDeps).then(
            (entries) => factory.createRootContext?.(Object.fromEntries(entries))
          ).catch((error) => {
            const cause = errors.stringifyError(error);
            throw new Error(
              `Failed to instantiate service '${ref.id}' because createRootContext threw an error, ${cause}`
            );
          }),
          byPlugin: /* @__PURE__ */ new Map()
        };
        this.#implementations.set(factory, implementation);
      }
      let result = implementation.byPlugin.get(pluginId);
      if (!result) {
        const allDeps = new Array();
        for (const [name, serviceRef] of Object.entries(factory.deps)) {
          const target = this.get(serviceRef, pluginId);
          allDeps.push(target.then((impl) => [name, impl]));
        }
        result = implementation.context.then(
          (context) => Promise.all(allDeps).then(
            (entries) => factory.factory(Object.fromEntries(entries), context)
          )
        ).catch((error) => {
          const cause = errors.stringifyError(error);
          throw new Error(
            `Failed to instantiate service '${ref.id}' for '${pluginId}' because the factory function threw an error, ${cause}`
          );
        });
        implementation.byPlugin.set(pluginId, result);
      }
      return result;
    });
  }
}

class ServiceFactoryTester {
  #subject;
  #registry;
  /**
   * Creates a new {@link ServiceFactoryTester} used to test the provided subject.
   *
   * @param subject - The service factory to test.
   * @param options - Additional options
   * @returns A new tester instance for the provided subject.
   */
  static from(subject, options) {
    const registry = ServiceRegistry.create([
      ...defaultServiceFactories,
      ...options?.dependencies ?? [],
      subject
    ]);
    return new ServiceFactoryTester(subject.service, registry);
  }
  constructor(subject, registry) {
    this.#subject = subject;
    this.#registry = registry;
  }
  /**
   * Returns the service instance for the subject.
   *
   * @deprecated Use `getSubject` instead.
   */
  async get(...args) {
    return this.getSubject(...args);
  }
  /**
   * Returns the service instance for the subject.
   *
   * @remarks
   *
   * If the subject is a plugin scoped service factory a plugin ID
   * can be provided to instantiate the service for a specific plugin.
   *
   * By default the plugin ID 'test' is used.
   */
  async getSubject(...args) {
    const [pluginId] = args;
    return this.#registry.get(this.#subject, pluginId ?? "test");
  }
  /**
   * Return the service instance for any of the provided dependencies or built-in services.
   *
   * @remarks
   *
   * A plugin ID can optionally be provided for plugin scoped services, otherwise the plugin ID 'test' is used.
   */
  async getService(service, ...args) {
    const [pluginId] = args;
    const instance = await this.#registry.get(service, pluginId ?? "test");
    if (instance === void 0) {
      throw new Error(`Service '${service.id}' not found`);
    }
    return instance;
  }
}

exports.ServiceFactoryTester = ServiceFactoryTester;
exports.TestCaches = TestCaches;
exports.TestDatabases = TestDatabases;
exports.createMockDirectory = createMockDirectory;
exports.isDockerDisabledForTests = isDockerDisabledForTests;
exports.registerMswTestHooks = registerMswTestHooks;
exports.setupRequestMockHandlers = setupRequestMockHandlers;
exports.startTestBackend = startTestBackend;
//# sourceMappingURL=index.cjs.js.map
